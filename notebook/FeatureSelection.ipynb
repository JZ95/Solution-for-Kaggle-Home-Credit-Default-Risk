{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from scipy.stats import norm\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm_notebook\n",
    "import lightgbm as lgb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LGBMClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('../input/train_df.csv', nrows=10000)\n",
    "# feats = [f for f in train_df.columns if f not in [\n",
    "#         'TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'index']]\n",
    "X, y = train_df[feats], train_df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='rf', class_weight=None, colsample_bytree=0.75,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=0.75,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = LGBMClassifier('rf', subsample=0.75, subsample_freq=1, colsample_bytree=0.75)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "\n",
    "class PIMP:\n",
    "    \"\"\"Permutaion Importance for correcting the biased RF feature importance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shuffle_times=50, alpha=0.05):\n",
    "        self.__shuffle_times = shuffle_times\n",
    "        self.__alpha = alpha\n",
    "\n",
    "    # def fit(self, X, y):\n",
    "    #     self.__clf.fit(X, y)\n",
    "    #     actImp = self.__clf.feature_importances_\n",
    "    #     # n_rows - #features, n_cols - #shuffle\n",
    "    #     n_rows, n_cols = X.shape[1], self.__shuffle_times\n",
    "    #     nullImp = np.zeros((n_rows, n_cols))\n",
    "    #     for i in tqdm_notebook(range(n_cols)):\n",
    "    #         clf = deepcopy(self.__clf)\n",
    "    #         np.random.shuffle(y)\n",
    "    #         clf.fit(X, y)\n",
    "    #         nullImp[:, i] = clf.feature_importances_\n",
    "\n",
    "    #     miu = np.mean(nullImp, axis=1)\n",
    "    #     sigma = np.std(nullImp, axis=1)\n",
    "    #     mean_sigma = np.mean(sigma)\n",
    "    #     sigma[sigma < mean_sigma] = mean_sigma\n",
    "    #     correctImp = np.zeros((n_rows,))\n",
    "\n",
    "    #     for j in range(n_rows):\n",
    "    #         normDist = norm(miu[j], sigma[j])\n",
    "    #         correctImp[j] = 1 - normDist.cdf(actImp[j])\n",
    "\n",
    "    #     self.__feature_importances = correctImp\n",
    "    #     self.__significant_feats = np.argwhere(\n",
    "    #         correctImp < self.__alpha).ravel()\n",
    "    #     self.__actImp = actImp\n",
    "    #     self.__nullImp = nullImp\n",
    "\n",
    "    def run(self, X, y):\n",
    "        data = lgb.Dataset(X, y, free_raw_data=False, silent=True)\n",
    "        lgb_params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'rf',\n",
    "            'subsample': 0.85,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'num_leaves': 127,\n",
    "            'max_depth': -1,\n",
    "            'bagging_freq': 1,\n",
    "            'num_threads': 16,\n",
    "        }\n",
    "#         print('Obtaining ACTUAL IMP ...')\n",
    "#         clf = lgb.train(params=lgb_params, train_set=data, num_boost_round=250)\n",
    "#         actImp = clf.feature_importance('gain')\n",
    "        # n_rows - #features, n_cols - #shuffle\n",
    "        n_rows, n_cols = X.shape[1], self.__shuffle_times\n",
    "\n",
    "        nullImp = np.zeros((n_rows, n_cols))\n",
    "        print('SHUFFLE STAGE ...')\n",
    "        print('=' * 65)\n",
    "        for i in tqdm(range(n_cols)):\n",
    "            np.random.shuffle(y)\n",
    "            print(y[:100])\n",
    "            data.set_label(y)\n",
    "            clf = lgb.train(lgb_params, data, num_boost_round=250)\n",
    "            nullImp[:, i] = clf.feature_importance('gain')\n",
    "\n",
    "        miu = np.mean(nullImp, axis=1)\n",
    "        sigma = np.std(nullImp, axis=1)\n",
    "        mean_sigma = np.mean(sigma)\n",
    "        sigma[sigma < mean_sigma] = mean_sigma\n",
    "        correctImp = np.zeros((n_rows,))\n",
    "\n",
    "        for j in range(n_rows):\n",
    "            normDist = norm(miu[j], sigma[j])\n",
    "            correctImp[j] = 1 - normDist.cdf(actImp[j])\n",
    "\n",
    "        self.__feature_importances = correctImp\n",
    "        self.__significant_feats = np.argwhere(\n",
    "            correctImp < self.__alpha).ravel()\n",
    "        self.__actImp = actImp\n",
    "        self.__nullImp = nullImp\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return self.__feature_importances\n",
    "\n",
    "    @property\n",
    "    def significant_features_(self):\n",
    "        return self.__significant_feats\n",
    "\n",
    "    @property\n",
    "    def original_feature_importances_(self):\n",
    "        return self.__actImp\n",
    "\n",
    "    @property\n",
    "    def null_feature_importances_(self):\n",
    "        return self.__nullImp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_skip_i(i):\n",
    "    if np.random.uniform() > 0.45:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHUFFLE STAGE ...\n",
      "=================================================================\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [03:50<03:50, 230.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [07:05<00:00, 212.58s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'actImp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f3f71689bc12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     'TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'index']]\n\u001b[1;32m      6\u001b[0m \u001b[0mpImpCorrector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIMP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpImpCorrector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARGET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# pImpDf = pd.DataFrame(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     {'feats': feats,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6bde9ddaa576>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mnormDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmiu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mcorrectImp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnormDist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactImp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__feature_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrectImp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'actImp' is not defined"
     ]
    }
   ],
   "source": [
    "data_file_path = '../workdir/withAggFeatsIn/train_df.csv'\n",
    "train_df = pd.read_csv(data_file_path, skiprows=is_skip_i)\n",
    "# train_df = train_df.sample(frac=0.5, replace=False)\n",
    "feats = [f for f in train_df.columns if f not in [\n",
    "    'TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'index']]\n",
    "pImpCorrector = PIMP(2)\n",
    "pImpCorrector.run(train_df[feats], train_df['TARGET'].values)\n",
    "# pImpDf = pd.DataFrame(\n",
    "#     {'feats': feats,\n",
    "#      'pImp': pImpCorrector.feature_importances_,\n",
    "#      'actImp': pImpCorrector.original_feature_importances_, }\n",
    "# )\n",
    "# pImpDf['is_significant'] = False\n",
    "# pImpDf.loc[pImpCorrector.significant_features_, 'is_significant'] = True\n",
    "# nullImpDf = pd.DataFrame(pImpCorrector.null_feature_importances_)\n",
    "# nullImpDf.columns = pd.Index(['shuffle_%d' % (i + 1)\n",
    "#                               for i in range(nullImpDf.shape[1])])\n",
    "# df = pImpDf.join(nullImpDf)\n",
    "# df.set_index('feats', inplace=True)\n",
    "# df.to_csv('./PIMP_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotDist(actImp, nullImp):\n",
    "    n = len(actImp)\n",
    "    plt.figure(figsize=(12, 36))\n",
    "    for i in range(n):\n",
    "        plt.subplot(int(np.ceil(n / 2)), 2, i + 1)\n",
    "        height, _, _ = plt.hist(nullImp[i], label='nullImp')\n",
    "        plt.vlines(x=actImp[i], ymin=0, ymax=height.max(), label='actImp')\n",
    "        plt.legend()\n",
    "\n",
    "# plotDist(pImp.original_feature_importances_, pImp.null_feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
